{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with open('data/c_pairs_anon_scored.feb') as f:\n",
    "    content = f.read().splitlines()\n",
    "end = time.time()\n",
    "\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_paths = set()\n",
    "pairs = []\n",
    "paths = []\n",
    "meetings = []\n",
    "\n",
    "start = time.time()\n",
    "for i in xrange(len(content)):\n",
    "    if i % 10000000 == 0:\n",
    "        print i, ': ', time.time()-start\n",
    "    (id1, id2, path, count, numMeeting) = content[i].split('|')\n",
    "    pairs.append(''.join(sorted(list([id1, id2]))))\n",
    "    paths.append(path)\n",
    "    meetings.append(int(numMeeting))\n",
    "unique_paths = set(paths)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pdMeetings = pd.Series(meetings, index=pairs, dtype=np.uint8)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pdPaths = pd.Series(paths, index=pairs)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "feats = pd.get_dummies(pdPaths, sparse=True)\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "combinedFeats = pd.concat([feats, pdMeetings], axis=1).sample(frac=0.005)\n",
    "end = time.time()\n",
    "print end - start\n",
    "\n",
    "# combinedFeats.shape\n",
    "# (393169, 170)\n",
    "# %xdel combinedFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# relabel\n",
    "list1 = combinedFeats.columns.tolist()[:(len(combinedFeats.columns)-1)]\n",
    "list2 = ['numOfMeetings']\n",
    "list1.extend(list2)\n",
    "combinedFeats.columns = list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read February t_space data to create label vector\n",
    "start = time.time()\n",
    "\n",
    "with open('data/t_pairs_anon_verbs.feb.txt') as f:\n",
    "    content = f.read().splitlines()\n",
    "end = time.time()\n",
    "\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_unique_paths = set()\n",
    "t_pairs = []\n",
    "t_paths = []\n",
    "t_interactions = []\n",
    "\n",
    "start = time.time()\n",
    "for i in xrange(len(content)):\n",
    "    (id1, id2, verb, path, count, numInteraction) = content[i].split('|')\n",
    "    t_pairs.append(''.join(sorted(list([id1, id2]))))\n",
    "    t_paths.append(path)\n",
    "    t_interactions.append(int(numInteraction))\n",
    "t_unique_paths = set(t_paths)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove dups\n",
    "ut_pairs = []\n",
    "ut_paths = []\n",
    "\n",
    "start = time.time()\n",
    "for i in xrange(len(t_pairs)):\n",
    "    if t_pairs[i] not in ut_pairs:\n",
    "        ut_pairs.append(t_pairs[i])\n",
    "        ut_paths.append(t_paths[i])\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pdTPaths = pd.Series(ut_paths, index=ut_pairs)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "t_feats = pd.get_dummies(pdTPaths, sparse=True)\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign label '1' to all t_ examples\n",
    "t_labels = pd.Series(1, index=ut_pairs, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine and relabel\n",
    "start = time.time()\n",
    "t_combinedFeats = pd.concat([t_feats, t_labels], axis=1)\n",
    "end = time.time()\n",
    "print end - start\n",
    "\n",
    "list1 = t_combinedFeats.columns.tolist()[:(len(t_combinedFeats.columns)-1)]\n",
    "list2 = ['label']\n",
    "list1.extend(list2)\n",
    "t_combinedFeats.columns = list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine c_ and t_ examples (c_ contains mostly negative, t_ contains positive)\n",
    "start = time.time()\n",
    "combinedFeats = combinedFeats.to_dense()\n",
    "t_combinedFeats = t_combinedFeats.to_dense()\n",
    "training = pd.concat([combinedFeats, t_combinedFeats])\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove c_ and t_ overlapping ex, fill na\n",
    "training = training.reset_index()\n",
    "training = training[~training['index'].duplicated(keep='first')]\n",
    "training = training.fillna(0)\n",
    "training.index = training['index']\n",
    "# drop column\n",
    "training.drop(['index'], inplace=True,axis=1,errors='ignore')\n",
    "training = training.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recover num of meeting for positive training examples\n",
    "start = time.time()\n",
    "\n",
    "positiveTrainingEx = training.loc[training.label==1,:].index.intersection(pdMeetings.index)\n",
    "for hashId in positiveTrainingEx:\n",
    "    training.at[hashId, 'numOfMeetings'] = float(pdMeetings.at[hashId])\n",
    "\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trim negative examples a little more\n",
    "removes = []\n",
    "\n",
    "start = time.time()\n",
    "for hashId in training.index:\n",
    "    if training.at[hashId, 'label'] == 0:\n",
    "        if random.random() < 0.7:\n",
    "            removes.append(hashId)\n",
    "end = time.time()\n",
    "end - start\n",
    "\n",
    "training.drop(removes, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# export to file\n",
    "start = time.time()\n",
    "pickle.dump(training, open('trainFinal.p', 'wb'))\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.06825017929077"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "training = pickle.load(open('trainFinal.p', 'rb'))\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  0.000339984893799\n",
      "10000000 :  30.0450561047\n",
      "64.7921299934\n",
      "22.7406461239\n"
     ]
    }
   ],
   "source": [
    "# creating test set from c_ for Mar\n",
    "start = time.time()\n",
    "with open('data/c_uniq_pairs_anon_scored.mar') as f:\n",
    "    content = f.read().splitlines()\n",
    "end = time.time()\n",
    "end - start\n",
    "\n",
    "unique_paths = set()\n",
    "pairs = []\n",
    "paths = []\n",
    "meetings = []\n",
    "\n",
    "start = time.time()\n",
    "for i in xrange(len(content)):\n",
    "    if i % 10000000 == 0:\n",
    "        print i, ': ', time.time()-start\n",
    "    (id1, id2, path, count, numMeeting) = content[i].split('|')\n",
    "    pairs.append(''.join(sorted(list([id1, id2]))))\n",
    "    paths.append(path)\n",
    "    meetings.append(int(numMeeting))\n",
    "unique_paths = set(paths)\n",
    "end = time.time()\n",
    "end - start\n",
    "\n",
    "start = time.time()\n",
    "pdMeetings = pd.Series(meetings, index=pairs, dtype=np.uint8)\n",
    "end = time.time()\n",
    "end - start\n",
    "\n",
    "start = time.time()\n",
    "pdPaths = pd.Series(paths, index=pairs)\n",
    "end = time.time()\n",
    "end - start\n",
    "\n",
    "start = time.time()\n",
    "feats = pd.get_dummies(pdPaths, sparse=True)\n",
    "end = time.time()\n",
    "print end - start\n",
    "\n",
    "start = time.time()\n",
    "combinedFeatsT = pd.concat([feats, pdMeetings], axis=1).sample(frac=0.001)\n",
    "end = time.time()\n",
    "print end - start\n",
    "\n",
    "list1 = combinedFeatsT.columns.tolist()[:(len(combinedFeatsT.columns)-1)]\n",
    "list2 = ['numOfMeetings']\n",
    "list1.extend(list2)\n",
    "combinedFeatsT.columns = list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.147927045822\n",
      "0.0137979984283\n",
      "0.0137979984283\n"
     ]
    }
   ],
   "source": [
    "# getting t_ examples for Mar\n",
    "start = time.time()\n",
    "with open('data/t_pairs_anon.mar') as f:\n",
    "    content = f.read().splitlines()\n",
    "end = time.time()\n",
    "end - start\n",
    "\n",
    "t_unique_paths = set()\n",
    "t_pairs = []\n",
    "t_paths = []\n",
    "t_interactions = []\n",
    "\n",
    "start = time.time()\n",
    "for i in xrange(len(content)):\n",
    "    (id1, id2, path, count, numInteraction) = content[i].split('|')\n",
    "    t_pairs.append(''.join(sorted(list([id1, id2]))))\n",
    "    t_paths.append(path)\n",
    "    t_interactions.append(int(numInteraction))\n",
    "t_unique_paths = set(t_paths)\n",
    "end = time.time()\n",
    "end - start\n",
    "\n",
    "ut_pairs = []\n",
    "ut_paths = []\n",
    "\n",
    "start = time.time()\n",
    "for i in xrange(len(t_pairs)):\n",
    "    if t_pairs[i] not in ut_pairs:\n",
    "        ut_pairs.append(t_pairs[i])\n",
    "        ut_paths.append(t_paths[i])\n",
    "end = time.time()\n",
    "print end - start\n",
    "\n",
    "start = time.time()\n",
    "pdTPaths = pd.Series(ut_paths, index=ut_pairs)\n",
    "end = time.time()\n",
    "end - start\n",
    "\n",
    "start = time.time()\n",
    "t_feats = pd.get_dummies(pdTPaths, sparse=True)\n",
    "end = time.time()\n",
    "\n",
    "# assign label '1' to all t_ examples\n",
    "t_labels = pd.Series(1, index=ut_pairs, dtype=np.uint8)\n",
    "\n",
    "# combine and relabel\n",
    "start = time.time()\n",
    "t_combinedFeatsT = pd.concat([t_feats, t_labels], axis=1)\n",
    "end = time.time()\n",
    "print end - start\n",
    "\n",
    "list1 = t_combinedFeatsT.columns.tolist()[:(len(t_combinedFeatsT.columns)-1)]\n",
    "list2 = ['label']\n",
    "list1.extend(list2)\n",
    "t_combinedFeatsT.columns = list1\n",
    "\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11556601524353027"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the c_ examples that are in t_\n",
    "start = time.time()\n",
    "overlap = combinedFeatsT.index.intersection(t_feats.index)\n",
    "ins = []\n",
    "\n",
    "for i in xrange(len(combinedFeatsT)):\n",
    "    if combinedFeatsT.index[i] in overlap:\n",
    "        ins.append(False)\n",
    "    else:\n",
    "        ins.append(True)\n",
    "\n",
    "smallFeats = combinedFeatsT.loc[ins, :].to_dense()        \n",
    "\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04295992851257324"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine c_ and t_ for Mar\n",
    "start = time.time()\n",
    "smallFeats2 = smallFeats.to_dense()\n",
    "t_feats2 = t_combinedFeatsT.to_dense()\n",
    "testing = pd.concat([smallFeats2, t_feats2])\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine with a sample row from training to sync up on columns\n",
    "a = training[:1]\n",
    "testing = pd.concat([testing, a])\n",
    "testing.drop(a.index, inplace=True)\n",
    "\n",
    "# reindex, fill na, maintenance\n",
    "testing = testing.reset_index()\n",
    "testing = testing[~testing['index'].duplicated(keep='first')]\n",
    "testing = testing.fillna(0)\n",
    "testing.index = testing['index']\n",
    "testing.drop(['index'], inplace=True,axis=1,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012418985366821289"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove redundant columns\n",
    "start = time.time()\n",
    "\n",
    "cols = []\n",
    "for col in testing.columns:\n",
    "    if col not in training.columns:\n",
    "        cols.append(col)\n",
    "\n",
    "testing.drop(cols, inplace=True,axis=1,errors='ignore')\n",
    "\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1305899620056152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "pickle.dump(testing, open('testFinal.p', 'wb'))\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
